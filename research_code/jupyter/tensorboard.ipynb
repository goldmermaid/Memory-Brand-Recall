{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cPickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'total_recall_rate_airlines.csv', 'total_recall_rate_auto_insurance.csv', 'total_recall_rate_banks.csv', 'total_recall_rate_bar_soap.csv', 'total_recall_rate_batteries.csv', 'total_recall_rate_beers.csv', 'total_recall_rate_body_wash.csv', 'total_recall_rate_bottled_water.csv', 'total_recall_rate_breakfast_cereal.csv', 'total_recall_rate_chewing_gum.csv', 'total_recall_rate_energy_bar.csv', 'total_recall_rate_energy_drink.csv', 'total_recall_rate_fast_food.csv', 'total_recall_rate_gas_station.csv', 'total_recall_rate_Greek_yogurt.csv', 'total_recall_rate_headphone.csv', 'total_recall_rate_hotel.csv', 'total_recall_rate_jeans.csv', 'total_recall_rate_laptop.csv', 'total_recall_rate_laundry_detergent.csv', 'total_recall_rate_luxury_car.csv', 'total_recall_rate_orange_juice.csv', 'total_recall_rate_potato_chips.csv', 'total_recall_rate_running_shoes.csv', 'total_recall_rate_shampoo.csv', 'total_recall_rate_soda.csv', 'total_recall_rate_soft_drink.csv', 'total_recall_rate_television.csv', 'total_recall_rate_toilet_paper.csv', 'total_recall_rate_toothpaste.csv']\n"
     ]
    }
   ],
   "source": [
    "brands_to_ignore = [] \n",
    "with open('./polysemy_brands.txt') as f:\n",
    "    for i in f: brands_to_ignore.append(i.strip('\\n'))\n",
    "\n",
    "total_recall_summary_data_path = 'total_recall_summary_data'\n",
    "cat_dict = {}   ## A dict to save recall data : {'Greek_yogurt': {'Activia': 0.0288808664259928, 'Chobani': 0.18411552346570398,...}, {'Fast_food':...\n",
    "\n",
    "print(os.listdir(total_recall_summary_data_path))\n",
    "for p in os.listdir(total_recall_summary_data_path)[1:]:\n",
    "    df = pd.read_csv(total_recall_summary_data_path+'/'+p,index_col=0)\n",
    "    df = df[['Item_name','Recall_prop']].set_index('Item_name')\n",
    "    cat = p.replace('total_recall_rate_','').replace('.csv','')\n",
    "    cat_dict[cat] = df.to_dict()['Recall_prop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WordVectorRef</th>\n",
       "      <th>Category</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Closest_Word</th>\n",
       "      <th>Vector</th>\n",
       "      <th>Cosine</th>\n",
       "      <th>DotProduct</th>\n",
       "      <th>Recalls</th>\n",
       "      <th>Log_p/(1-p)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>McDonald's-fast_food-Word2vec</th>\n",
       "      <td>Word2vec</td>\n",
       "      <td>fast_food</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>[McDonald, mcdonald, McDonalds, McDonald's, mc...</td>\n",
       "      <td>[-0.16142578, 0.024047852, -0.042089842, 0.406...</td>\n",
       "      <td>0.589858</td>\n",
       "      <td>2.58753</td>\n",
       "      <td>0.97541</td>\n",
       "      <td>3.680511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KFC-fast_food-Word2vec</th>\n",
       "      <td>Word2vec</td>\n",
       "      <td>fast_food</td>\n",
       "      <td>KFC</td>\n",
       "      <td>[KFC, kfc]</td>\n",
       "      <td>[-0.20166016, 0.029907227, 0.016815186, 0.1708...</td>\n",
       "      <td>0.571534</td>\n",
       "      <td>2.58777</td>\n",
       "      <td>0.344262</td>\n",
       "      <td>-0.644357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dunkin Donuts-fast_food-Word2vec</th>\n",
       "      <td>Word2vec</td>\n",
       "      <td>fast_food</td>\n",
       "      <td>Dunkin Donuts</td>\n",
       "      <td>[dunkin_donuts, Dunkin_Donuts]</td>\n",
       "      <td>[-0.15893555, 0.048583984, -0.03338623, 0.3178...</td>\n",
       "      <td>0.50369</td>\n",
       "      <td>2.24768</td>\n",
       "      <td>0.0163934</td>\n",
       "      <td>-4.094345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Burger King-fast_food-Word2vec</th>\n",
       "      <td>Word2vec</td>\n",
       "      <td>fast_food</td>\n",
       "      <td>Burger King</td>\n",
       "      <td>[Burger_King]</td>\n",
       "      <td>[-0.12695312, 0.04296875, -0.09716797, 0.26757...</td>\n",
       "      <td>0.491929</td>\n",
       "      <td>3.55879</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>1.406914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taco Bell-fast_food-Word2vec</th>\n",
       "      <td>Word2vec</td>\n",
       "      <td>fast_food</td>\n",
       "      <td>Taco Bell</td>\n",
       "      <td>[Taco_Bell]</td>\n",
       "      <td>[-0.14550781, 0.20214844, -0.022583008, 0.4218...</td>\n",
       "      <td>0.475602</td>\n",
       "      <td>3.80053</td>\n",
       "      <td>0.713115</td>\n",
       "      <td>0.910560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 WordVectorRef   Category          Brand  \\\n",
       "McDonald's-fast_food-Word2vec         Word2vec  fast_food     McDonald's   \n",
       "KFC-fast_food-Word2vec                Word2vec  fast_food            KFC   \n",
       "Dunkin Donuts-fast_food-Word2vec      Word2vec  fast_food  Dunkin Donuts   \n",
       "Burger King-fast_food-Word2vec        Word2vec  fast_food    Burger King   \n",
       "Taco Bell-fast_food-Word2vec          Word2vec  fast_food      Taco Bell   \n",
       "\n",
       "                                                                       Closest_Word  \\\n",
       "McDonald's-fast_food-Word2vec     [McDonald, mcdonald, McDonalds, McDonald's, mc...   \n",
       "KFC-fast_food-Word2vec                                                   [KFC, kfc]   \n",
       "Dunkin Donuts-fast_food-Word2vec                     [dunkin_donuts, Dunkin_Donuts]   \n",
       "Burger King-fast_food-Word2vec                                        [Burger_King]   \n",
       "Taco Bell-fast_food-Word2vec                                            [Taco_Bell]   \n",
       "\n",
       "                                                                             Vector  \\\n",
       "McDonald's-fast_food-Word2vec     [-0.16142578, 0.024047852, -0.042089842, 0.406...   \n",
       "KFC-fast_food-Word2vec            [-0.20166016, 0.029907227, 0.016815186, 0.1708...   \n",
       "Dunkin Donuts-fast_food-Word2vec  [-0.15893555, 0.048583984, -0.03338623, 0.3178...   \n",
       "Burger King-fast_food-Word2vec    [-0.12695312, 0.04296875, -0.09716797, 0.26757...   \n",
       "Taco Bell-fast_food-Word2vec      [-0.14550781, 0.20214844, -0.022583008, 0.4218...   \n",
       "\n",
       "                                    Cosine DotProduct    Recalls  Log_p/(1-p)  \n",
       "McDonald's-fast_food-Word2vec     0.589858    2.58753    0.97541     3.680511  \n",
       "KFC-fast_food-Word2vec            0.571534    2.58777   0.344262    -0.644357  \n",
       "Dunkin Donuts-fast_food-Word2vec   0.50369    2.24768  0.0163934    -4.094345  \n",
       "Burger King-fast_food-Word2vec    0.491929    3.55879   0.803279     1.406914  \n",
       "Taco Bell-fast_food-Word2vec      0.475602    3.80053   0.713115     0.910560  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/Brands_4_Word_Vectors_all_closest/Brands_4_Word_Vectors_all_closest_remove_tuple_brand_df_averaged_similarity\", 'rb') as f:\n",
    "    vec_sim_df = cPickle.load(f)\n",
    "vec_sim_df[(vec_sim_df['Category']=='fast_food') &\n",
    "          (vec_sim_df['WordVectorRef']==\"Word2vec\")].sort_values(['Cosine'],ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Closest_Word</th>\n",
       "      <th>Vector</th>\n",
       "      <th>Category</th>\n",
       "      <th>WordVectorRef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Greek_yogurt-Greek_yogurt-Greek_yogurt-Word2vec</th>\n",
       "      <td>Greek_yogurt</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "      <td>[0.23144531, 0.14355469, -0.06542969, -0.12597...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "      <td>Word2vec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greek_yogurt-Greek_yogurt-('greek', 'yogurt')-Word2vec</th>\n",
       "      <td>Greek_yogurt</td>\n",
       "      <td>(greek, yogurt)</td>\n",
       "      <td>[-0.06323242, -0.07678223, 0.06738281, 0.21240...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "      <td>Word2vec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greek_yogurt-Greek_yogurt-greek_yogurt-Word2vec</th>\n",
       "      <td>Greek_yogurt</td>\n",
       "      <td>greek_yogurt</td>\n",
       "      <td>[-0.071777344, -0.040527344, 0.023071289, 0.05...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "      <td>Word2vec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>airlines-airlines-airlines-Word2vec</th>\n",
       "      <td>airlines</td>\n",
       "      <td>airlines</td>\n",
       "      <td>[0.23535156, -0.08544922, -0.00013828278, 0.53...</td>\n",
       "      <td>airlines</td>\n",
       "      <td>Word2vec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auto_insurance-auto_insurance-('auto', 'insurance')-Word2vec</th>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>(auto, insurance)</td>\n",
       "      <td>[0.110961914, 0.12451172, 0.059814453, 0.16503...</td>\n",
       "      <td>auto_insurance</td>\n",
       "      <td>Word2vec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Brand  \\\n",
       "Greek_yogurt-Greek_yogurt-Greek_yogurt-Word2vec       Greek_yogurt   \n",
       "Greek_yogurt-Greek_yogurt-('greek', 'yogurt')-W...    Greek_yogurt   \n",
       "Greek_yogurt-Greek_yogurt-greek_yogurt-Word2vec       Greek_yogurt   \n",
       "airlines-airlines-airlines-Word2vec                       airlines   \n",
       "auto_insurance-auto_insurance-('auto', 'insuran...  auto_insurance   \n",
       "\n",
       "                                                         Closest_Word  \\\n",
       "Greek_yogurt-Greek_yogurt-Greek_yogurt-Word2vec          Greek_yogurt   \n",
       "Greek_yogurt-Greek_yogurt-('greek', 'yogurt')-W...    (greek, yogurt)   \n",
       "Greek_yogurt-Greek_yogurt-greek_yogurt-Word2vec          greek_yogurt   \n",
       "airlines-airlines-airlines-Word2vec                          airlines   \n",
       "auto_insurance-auto_insurance-('auto', 'insuran...  (auto, insurance)   \n",
       "\n",
       "                                                                                               Vector  \\\n",
       "Greek_yogurt-Greek_yogurt-Greek_yogurt-Word2vec     [0.23144531, 0.14355469, -0.06542969, -0.12597...   \n",
       "Greek_yogurt-Greek_yogurt-('greek', 'yogurt')-W...  [-0.06323242, -0.07678223, 0.06738281, 0.21240...   \n",
       "Greek_yogurt-Greek_yogurt-greek_yogurt-Word2vec     [-0.071777344, -0.040527344, 0.023071289, 0.05...   \n",
       "airlines-airlines-airlines-Word2vec                 [0.23535156, -0.08544922, -0.00013828278, 0.53...   \n",
       "auto_insurance-auto_insurance-('auto', 'insuran...  [0.110961914, 0.12451172, 0.059814453, 0.16503...   \n",
       "\n",
       "                                                          Category  \\\n",
       "Greek_yogurt-Greek_yogurt-Greek_yogurt-Word2vec       Greek_yogurt   \n",
       "Greek_yogurt-Greek_yogurt-('greek', 'yogurt')-W...    Greek_yogurt   \n",
       "Greek_yogurt-Greek_yogurt-greek_yogurt-Word2vec       Greek_yogurt   \n",
       "airlines-airlines-airlines-Word2vec                       airlines   \n",
       "auto_insurance-auto_insurance-('auto', 'insuran...  auto_insurance   \n",
       "\n",
       "                                                   WordVectorRef  \n",
       "Greek_yogurt-Greek_yogurt-Greek_yogurt-Word2vec         Word2vec  \n",
       "Greek_yogurt-Greek_yogurt-('greek', 'yogurt')-W...      Word2vec  \n",
       "Greek_yogurt-Greek_yogurt-greek_yogurt-Word2vec         Word2vec  \n",
       "airlines-airlines-airlines-Word2vec                     Word2vec  \n",
       "auto_insurance-auto_insurance-('auto', 'insuran...      Word2vec  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cPickle\n",
    "\n",
    "with open(\"data/Brands_4_Word_Vectors_all_closest/Brands_4_Word_Vectors_all_closest_all_individual_remove_tuple_brand_df_averaged\", 'rb') as f:\n",
    "    vec_avg_df = cPickle.load(f)\n",
    "vec_avg_df.columns\n",
    "\n",
    "with open(\"data/Brands_4_Word_Vectors_all_closest/Brands_4_Word_Vectors_all_closest_all_individual_remove_tuple_brand_df\", 'rb') as f:\n",
    "    vec_df = cPickle.load(f)\n",
    "vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Vector</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Closest_Word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>airlines</th>\n",
       "      <td>airlines-airlines-airlines-Wiki</td>\n",
       "      <td>[0.68775, -0.30703, 0.16407, 0.064477, 0.48053...</td>\n",
       "      <td>airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banks</th>\n",
       "      <td>banks-banks-banks-Wiki</td>\n",
       "      <td>[-0.043998, -0.1459, -0.3264, -0.19623, 0.5203...</td>\n",
       "      <td>banks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batteries</th>\n",
       "      <td>batteries-batteries-batteries-Wiki</td>\n",
       "      <td>[-0.20282, 0.15957, -0.53571, -0.29621, -0.156...</td>\n",
       "      <td>batteries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beers</th>\n",
       "      <td>beers-beers-beers-Wiki</td>\n",
       "      <td>[-0.45907, 0.74905, -0.65789, 0.35782, -0.7025...</td>\n",
       "      <td>beers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fastfood</th>\n",
       "      <td>fast_food-fast_food-fastfood-Wiki</td>\n",
       "      <td>[0.62266, 0.28842, 0.089707, -0.12507, 0.24438...</td>\n",
       "      <td>fast_food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headphone</th>\n",
       "      <td>headphone-headphone-headphone-Wiki</td>\n",
       "      <td>[0.11864, 0.16334, -0.090454, 0.075418, 0.2029...</td>\n",
       "      <td>headphone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hotel</th>\n",
       "      <td>hotel-hotel-hotel-Wiki</td>\n",
       "      <td>[0.020612, 0.3291, -0.016189, -0.067513, 0.101...</td>\n",
       "      <td>hotel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeans</th>\n",
       "      <td>jeans-jeans-jeans-Wiki</td>\n",
       "      <td>[-0.067237, 0.092779, 0.046291, 0.027839, -0.2...</td>\n",
       "      <td>jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>laptop</th>\n",
       "      <td>laptop-laptop-laptop-Wiki</td>\n",
       "      <td>[-0.31974, 0.099409, -0.43893, -0.62199, -0.00...</td>\n",
       "      <td>laptop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shampoo</th>\n",
       "      <td>shampoo-shampoo-shampoo-Wiki</td>\n",
       "      <td>[0.22742, 0.28665, -0.11011, 0.078492, -0.3473...</td>\n",
       "      <td>shampoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>softdrink</th>\n",
       "      <td>soft_drink-soft_drink-softdrink-Wiki</td>\n",
       "      <td>[0.33288, -0.1351, -0.0032981, -0.12126, -0.15...</td>\n",
       "      <td>soft_drink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>television</th>\n",
       "      <td>television-television-television-Wiki</td>\n",
       "      <td>[-0.010235, 0.49734, 0.43753, 0.20773, -0.1851...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toothpaste</th>\n",
       "      <td>toothpaste-toothpaste-toothpaste-Wiki</td>\n",
       "      <td>[0.59134, 0.77031, -0.088157, -0.13685, -0.072...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>activia</th>\n",
       "      <td>Greek_yogurt-Activia-activia-Wiki</td>\n",
       "      <td>[0.5769, 0.085894, 0.16225, -0.10494, -0.13723...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dannon</th>\n",
       "      <td>Greek_yogurt-Dannon-dannon-Wiki</td>\n",
       "      <td>[0.25281, 0.20593, 0.20898, 0.11406, 0.12384, ...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fage</th>\n",
       "      <td>Greek_yogurt-Fage-fage-Wiki</td>\n",
       "      <td>[0.35764, 0.53916, -0.02909, 0.33497, -0.29146...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kroger</th>\n",
       "      <td>Greek_yogurt-Kroger-kroger-Wiki</td>\n",
       "      <td>[0.21933, 0.51661, 0.40877, 0.20943, 0.48115, ...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noosa</th>\n",
       "      <td>Greek_yogurt-Noosa-noosa-Wiki</td>\n",
       "      <td>[-0.54803, -0.69976, -0.47428, -0.12807, 0.571...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oikos</th>\n",
       "      <td>Greek_yogurt-Oikos-oikos-Wiki</td>\n",
       "      <td>[0.16848, 0.099226, 0.35417, 0.5777, 0.071931,...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siggi</th>\n",
       "      <td>Greek_yogurt-Siggi's-siggi-Wiki</td>\n",
       "      <td>[-0.2653, 0.11347, -0.33941, 0.4279, 0.54777, ...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stonyfield</th>\n",
       "      <td>Greek_yogurt-Stonyfield-stonyfield-Wiki</td>\n",
       "      <td>[-0.22593, -0.07296, -0.42752, -0.015823, 0.31...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tillamook</th>\n",
       "      <td>Greek_yogurt-Tillamook-tillamook-Wiki</td>\n",
       "      <td>[-0.31975, -0.14055, 0.30642, 0.026534, -0.161...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>Greek_yogurt-Total-total-Wiki</td>\n",
       "      <td>[-0.60433, 0.56631, 0.067642, 0.25404, -0.5631...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wallaby</th>\n",
       "      <td>Greek_yogurt-Wallaby-wallaby-Wiki</td>\n",
       "      <td>[0.53795, 0.34255, -0.30817, -0.29715, 0.74547...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yoplait</th>\n",
       "      <td>Greek_yogurt-Yoplait-yoplait-Wiki</td>\n",
       "      <td>[0.56207, 0.0034669, 0.79792, -0.82226, 0.1827...</td>\n",
       "      <td>Greek_yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alaska</th>\n",
       "      <td>airlines-Alaska-alaska-Wiki</td>\n",
       "      <td>[0.026957, 0.27307, -0.22391, 0.23416, -0.1172...</td>\n",
       "      <td>airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allegiant</th>\n",
       "      <td>airlines-Allegiant-allegiant-Wiki</td>\n",
       "      <td>[0.26776, -0.051443, 0.21437, 0.55177, 0.40692...</td>\n",
       "      <td>airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>american</th>\n",
       "      <td>airlines-American-american-Wiki</td>\n",
       "      <td>[0.28417, 0.11386, 0.16274, 0.21845, -0.21082,...</td>\n",
       "      <td>airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>continental</th>\n",
       "      <td>airlines-Continental-continental-Wiki</td>\n",
       "      <td>[0.70841, 0.31371, -0.31746, -0.12675, 0.11917...</td>\n",
       "      <td>airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>airlines-Delta-delta-Wiki</td>\n",
       "      <td>[0.47946, 0.23099, -0.11539, -0.18388, 0.14388...</td>\n",
       "      <td>airlines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insignia</th>\n",
       "      <td>television-Insignia-insignia-Wiki</td>\n",
       "      <td>[-0.030002, -0.11037, -0.19132, 0.31985, -0.41...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jvc</th>\n",
       "      <td>television-JVC-jvc-Wiki</td>\n",
       "      <td>[0.18707, -0.046907, -0.042823, -0.24225, -0.0...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lg</th>\n",
       "      <td>television-LG-lg-Wiki</td>\n",
       "      <td>[0.24636, 0.87451, -0.75376, -0.03305, -0.1339...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>magnavox</th>\n",
       "      <td>television-Magnavox-magnavox-Wiki</td>\n",
       "      <td>[0.75013, 0.72063, -0.29448, 0.77554, 0.40225,...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mitsubishi</th>\n",
       "      <td>television-Mitsubishi-mitsubishi-Wiki</td>\n",
       "      <td>[0.13863, 0.4605, -0.35182, -0.43078, -0.61536...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>panasonic</th>\n",
       "      <td>television-Panasonic-panasonic-Wiki</td>\n",
       "      <td>[0.91485, 0.84019, -0.074749, -0.33506, -0.114...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phillips</th>\n",
       "      <td>television-Phillips-phillips-Wiki</td>\n",
       "      <td>[-0.13338, 0.20024, 0.036971, 0.78335, -0.1550...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rca</th>\n",
       "      <td>television-RCA-rca-Wiki</td>\n",
       "      <td>[0.82243, 0.011848, -0.15003, 0.22044, -0.3482...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samsung</th>\n",
       "      <td>television-Samsung-samsung-Wiki</td>\n",
       "      <td>[-0.21939, 0.81376, -0.43695, -0.47778, -0.370...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharp</th>\n",
       "      <td>television-Sharp-sharp-Wiki</td>\n",
       "      <td>[0.18208, -0.010888, -0.043777, -0.17397, -0.2...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sony</th>\n",
       "      <td>television-Sony-sony-Wiki</td>\n",
       "      <td>[0.09733, -0.098604, 0.08156, -0.18296, -0.471...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toshiba</th>\n",
       "      <td>television-Toshiba-toshiba-Wiki</td>\n",
       "      <td>[0.0091066, 0.12493, -0.29419, -0.7064, -0.349...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vizio</th>\n",
       "      <td>television-Vizio-vizio-Wiki</td>\n",
       "      <td>[0.60343, 0.39626, 0.11692, 0.4556, -0.22739, ...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>westinghouse</th>\n",
       "      <td>television-Westinghouse-westinghouse-Wiki</td>\n",
       "      <td>[0.3246, -0.13166, 0.019156, -0.84825, -0.5203...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zenith</th>\n",
       "      <td>television-Zenith-zenith-Wiki</td>\n",
       "      <td>[0.64094, 0.058956, 0.51007, -0.40324, 0.05645...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bounty</th>\n",
       "      <td>toilet_paper-Bounty-bounty-Wiki</td>\n",
       "      <td>[-0.27114, 0.0039743, 0.41335, 0.31429, 0.3537...</td>\n",
       "      <td>toilet_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brawny</th>\n",
       "      <td>toilet_paper-Brawny-brawny-Wiki</td>\n",
       "      <td>[-0.010337, 0.24002, 0.21467, -0.73017, 0.0796...</td>\n",
       "      <td>toilet_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charmin</th>\n",
       "      <td>toilet_paper-Charmin-charmin-Wiki</td>\n",
       "      <td>[0.44189, 0.26375, 0.47391, -0.02577, -0.36937...</td>\n",
       "      <td>toilet_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cottonelle</th>\n",
       "      <td>toilet_paper-Cottonelle-cottonelle-Wiki</td>\n",
       "      <td>[0.73833, 0.23732, 0.58557, -0.26693, 0.21352,...</td>\n",
       "      <td>toilet_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scott</th>\n",
       "      <td>toilet_paper-Scott-scott-Wiki</td>\n",
       "      <td>[0.16277, -0.050784, -0.11452, -0.38196, 0.175...</td>\n",
       "      <td>toilet_paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aim</th>\n",
       "      <td>toothpaste-Aim-aim-Wiki</td>\n",
       "      <td>[0.07059, 0.34098, 0.046948, 0.02221, 0.31844,...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aquafresh</th>\n",
       "      <td>toothpaste-AquaFresh-aquafresh-Wiki</td>\n",
       "      <td>[0.3056, -0.21332, 0.21951, 0.2905, -0.11236, ...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>close-up</th>\n",
       "      <td>toothpaste-Close-Up-close-up-Wiki</td>\n",
       "      <td>[-0.23422, 0.43214, -0.45853, -0.54502, 0.0077...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colgate</th>\n",
       "      <td>toothpaste-Colgate-colgate-Wiki</td>\n",
       "      <td>[0.040379, 0.2478, 0.23818, 0.49231, -0.068767...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crest</th>\n",
       "      <td>toothpaste-Crest-crest-Wiki</td>\n",
       "      <td>[-0.24848, 0.25386, -0.16303, -0.48535, -0.128...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jason</th>\n",
       "      <td>toothpaste-Jason-jason-Wiki</td>\n",
       "      <td>[-0.0033165, 0.15623, -0.34174, 0.58501, 0.115...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mentadent</th>\n",
       "      <td>toothpaste-Mentadent-mentadent-Wiki</td>\n",
       "      <td>[0.19477, 0.57463, 0.41234, 0.61217, -0.19467,...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pepsodent</th>\n",
       "      <td>toothpaste-Pepsodent-pepsodent-Wiki</td>\n",
       "      <td>[-0.25594, 0.32515, -0.3657, 0.12705, -0.19359...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rembrandt</th>\n",
       "      <td>toothpaste-Rembrandt-rembrandt-Wiki</td>\n",
       "      <td>[0.83686, -0.4385, -0.43216, 0.61333, 0.38652,...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trident</th>\n",
       "      <td>toothpaste-Trident-trident-Wiki</td>\n",
       "      <td>[0.081471, 0.035272, 0.27418, 0.21987, -0.1931...</td>\n",
       "      <td>toothpaste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  index  \\\n",
       "Closest_Word                                              \n",
       "airlines                airlines-airlines-airlines-Wiki   \n",
       "banks                            banks-banks-banks-Wiki   \n",
       "batteries            batteries-batteries-batteries-Wiki   \n",
       "beers                            beers-beers-beers-Wiki   \n",
       "fastfood              fast_food-fast_food-fastfood-Wiki   \n",
       "headphone            headphone-headphone-headphone-Wiki   \n",
       "hotel                            hotel-hotel-hotel-Wiki   \n",
       "jeans                            jeans-jeans-jeans-Wiki   \n",
       "laptop                        laptop-laptop-laptop-Wiki   \n",
       "shampoo                    shampoo-shampoo-shampoo-Wiki   \n",
       "softdrink          soft_drink-soft_drink-softdrink-Wiki   \n",
       "television        television-television-television-Wiki   \n",
       "toothpaste        toothpaste-toothpaste-toothpaste-Wiki   \n",
       "activia               Greek_yogurt-Activia-activia-Wiki   \n",
       "dannon                  Greek_yogurt-Dannon-dannon-Wiki   \n",
       "fage                        Greek_yogurt-Fage-fage-Wiki   \n",
       "kroger                  Greek_yogurt-Kroger-kroger-Wiki   \n",
       "noosa                     Greek_yogurt-Noosa-noosa-Wiki   \n",
       "oikos                     Greek_yogurt-Oikos-oikos-Wiki   \n",
       "siggi                   Greek_yogurt-Siggi's-siggi-Wiki   \n",
       "stonyfield      Greek_yogurt-Stonyfield-stonyfield-Wiki   \n",
       "tillamook         Greek_yogurt-Tillamook-tillamook-Wiki   \n",
       "total                     Greek_yogurt-Total-total-Wiki   \n",
       "wallaby               Greek_yogurt-Wallaby-wallaby-Wiki   \n",
       "yoplait               Greek_yogurt-Yoplait-yoplait-Wiki   \n",
       "alaska                      airlines-Alaska-alaska-Wiki   \n",
       "allegiant             airlines-Allegiant-allegiant-Wiki   \n",
       "american                airlines-American-american-Wiki   \n",
       "continental       airlines-Continental-continental-Wiki   \n",
       "delta                         airlines-Delta-delta-Wiki   \n",
       "...                                                 ...   \n",
       "insignia              television-Insignia-insignia-Wiki   \n",
       "jvc                             television-JVC-jvc-Wiki   \n",
       "lg                                television-LG-lg-Wiki   \n",
       "magnavox              television-Magnavox-magnavox-Wiki   \n",
       "mitsubishi        television-Mitsubishi-mitsubishi-Wiki   \n",
       "panasonic           television-Panasonic-panasonic-Wiki   \n",
       "phillips              television-Phillips-phillips-Wiki   \n",
       "rca                             television-RCA-rca-Wiki   \n",
       "samsung                 television-Samsung-samsung-Wiki   \n",
       "sharp                       television-Sharp-sharp-Wiki   \n",
       "sony                          television-Sony-sony-Wiki   \n",
       "toshiba                 television-Toshiba-toshiba-Wiki   \n",
       "vizio                       television-Vizio-vizio-Wiki   \n",
       "westinghouse  television-Westinghouse-westinghouse-Wiki   \n",
       "zenith                    television-Zenith-zenith-Wiki   \n",
       "bounty                  toilet_paper-Bounty-bounty-Wiki   \n",
       "brawny                  toilet_paper-Brawny-brawny-Wiki   \n",
       "charmin               toilet_paper-Charmin-charmin-Wiki   \n",
       "cottonelle      toilet_paper-Cottonelle-cottonelle-Wiki   \n",
       "scott                     toilet_paper-Scott-scott-Wiki   \n",
       "aim                             toothpaste-Aim-aim-Wiki   \n",
       "aquafresh           toothpaste-AquaFresh-aquafresh-Wiki   \n",
       "close-up              toothpaste-Close-Up-close-up-Wiki   \n",
       "colgate                 toothpaste-Colgate-colgate-Wiki   \n",
       "crest                       toothpaste-Crest-crest-Wiki   \n",
       "jason                       toothpaste-Jason-jason-Wiki   \n",
       "mentadent           toothpaste-Mentadent-mentadent-Wiki   \n",
       "pepsodent           toothpaste-Pepsodent-pepsodent-Wiki   \n",
       "rembrandt           toothpaste-Rembrandt-rembrandt-Wiki   \n",
       "trident                 toothpaste-Trident-trident-Wiki   \n",
       "\n",
       "                                                         Vector      Category  \n",
       "Closest_Word                                                                   \n",
       "airlines      [0.68775, -0.30703, 0.16407, 0.064477, 0.48053...      airlines  \n",
       "banks         [-0.043998, -0.1459, -0.3264, -0.19623, 0.5203...         banks  \n",
       "batteries     [-0.20282, 0.15957, -0.53571, -0.29621, -0.156...     batteries  \n",
       "beers         [-0.45907, 0.74905, -0.65789, 0.35782, -0.7025...         beers  \n",
       "fastfood      [0.62266, 0.28842, 0.089707, -0.12507, 0.24438...     fast_food  \n",
       "headphone     [0.11864, 0.16334, -0.090454, 0.075418, 0.2029...     headphone  \n",
       "hotel         [0.020612, 0.3291, -0.016189, -0.067513, 0.101...         hotel  \n",
       "jeans         [-0.067237, 0.092779, 0.046291, 0.027839, -0.2...         jeans  \n",
       "laptop        [-0.31974, 0.099409, -0.43893, -0.62199, -0.00...        laptop  \n",
       "shampoo       [0.22742, 0.28665, -0.11011, 0.078492, -0.3473...       shampoo  \n",
       "softdrink     [0.33288, -0.1351, -0.0032981, -0.12126, -0.15...    soft_drink  \n",
       "television    [-0.010235, 0.49734, 0.43753, 0.20773, -0.1851...    television  \n",
       "toothpaste    [0.59134, 0.77031, -0.088157, -0.13685, -0.072...    toothpaste  \n",
       "activia       [0.5769, 0.085894, 0.16225, -0.10494, -0.13723...  Greek_yogurt  \n",
       "dannon        [0.25281, 0.20593, 0.20898, 0.11406, 0.12384, ...  Greek_yogurt  \n",
       "fage          [0.35764, 0.53916, -0.02909, 0.33497, -0.29146...  Greek_yogurt  \n",
       "kroger        [0.21933, 0.51661, 0.40877, 0.20943, 0.48115, ...  Greek_yogurt  \n",
       "noosa         [-0.54803, -0.69976, -0.47428, -0.12807, 0.571...  Greek_yogurt  \n",
       "oikos         [0.16848, 0.099226, 0.35417, 0.5777, 0.071931,...  Greek_yogurt  \n",
       "siggi         [-0.2653, 0.11347, -0.33941, 0.4279, 0.54777, ...  Greek_yogurt  \n",
       "stonyfield    [-0.22593, -0.07296, -0.42752, -0.015823, 0.31...  Greek_yogurt  \n",
       "tillamook     [-0.31975, -0.14055, 0.30642, 0.026534, -0.161...  Greek_yogurt  \n",
       "total         [-0.60433, 0.56631, 0.067642, 0.25404, -0.5631...  Greek_yogurt  \n",
       "wallaby       [0.53795, 0.34255, -0.30817, -0.29715, 0.74547...  Greek_yogurt  \n",
       "yoplait       [0.56207, 0.0034669, 0.79792, -0.82226, 0.1827...  Greek_yogurt  \n",
       "alaska        [0.026957, 0.27307, -0.22391, 0.23416, -0.1172...      airlines  \n",
       "allegiant     [0.26776, -0.051443, 0.21437, 0.55177, 0.40692...      airlines  \n",
       "american      [0.28417, 0.11386, 0.16274, 0.21845, -0.21082,...      airlines  \n",
       "continental   [0.70841, 0.31371, -0.31746, -0.12675, 0.11917...      airlines  \n",
       "delta         [0.47946, 0.23099, -0.11539, -0.18388, 0.14388...      airlines  \n",
       "...                                                         ...           ...  \n",
       "insignia      [-0.030002, -0.11037, -0.19132, 0.31985, -0.41...    television  \n",
       "jvc           [0.18707, -0.046907, -0.042823, -0.24225, -0.0...    television  \n",
       "lg            [0.24636, 0.87451, -0.75376, -0.03305, -0.1339...    television  \n",
       "magnavox      [0.75013, 0.72063, -0.29448, 0.77554, 0.40225,...    television  \n",
       "mitsubishi    [0.13863, 0.4605, -0.35182, -0.43078, -0.61536...    television  \n",
       "panasonic     [0.91485, 0.84019, -0.074749, -0.33506, -0.114...    television  \n",
       "phillips      [-0.13338, 0.20024, 0.036971, 0.78335, -0.1550...    television  \n",
       "rca           [0.82243, 0.011848, -0.15003, 0.22044, -0.3482...    television  \n",
       "samsung       [-0.21939, 0.81376, -0.43695, -0.47778, -0.370...    television  \n",
       "sharp         [0.18208, -0.010888, -0.043777, -0.17397, -0.2...    television  \n",
       "sony          [0.09733, -0.098604, 0.08156, -0.18296, -0.471...    television  \n",
       "toshiba       [0.0091066, 0.12493, -0.29419, -0.7064, -0.349...    television  \n",
       "vizio         [0.60343, 0.39626, 0.11692, 0.4556, -0.22739, ...    television  \n",
       "westinghouse  [0.3246, -0.13166, 0.019156, -0.84825, -0.5203...    television  \n",
       "zenith        [0.64094, 0.058956, 0.51007, -0.40324, 0.05645...    television  \n",
       "bounty        [-0.27114, 0.0039743, 0.41335, 0.31429, 0.3537...  toilet_paper  \n",
       "brawny        [-0.010337, 0.24002, 0.21467, -0.73017, 0.0796...  toilet_paper  \n",
       "charmin       [0.44189, 0.26375, 0.47391, -0.02577, -0.36937...  toilet_paper  \n",
       "cottonelle    [0.73833, 0.23732, 0.58557, -0.26693, 0.21352,...  toilet_paper  \n",
       "scott         [0.16277, -0.050784, -0.11452, -0.38196, 0.175...  toilet_paper  \n",
       "aim           [0.07059, 0.34098, 0.046948, 0.02221, 0.31844,...    toothpaste  \n",
       "aquafresh     [0.3056, -0.21332, 0.21951, 0.2905, -0.11236, ...    toothpaste  \n",
       "close-up      [-0.23422, 0.43214, -0.45853, -0.54502, 0.0077...    toothpaste  \n",
       "colgate       [0.040379, 0.2478, 0.23818, 0.49231, -0.068767...    toothpaste  \n",
       "crest         [-0.24848, 0.25386, -0.16303, -0.48535, -0.128...    toothpaste  \n",
       "jason         [-0.0033165, 0.15623, -0.34174, 0.58501, 0.115...    toothpaste  \n",
       "mentadent     [0.19477, 0.57463, 0.41234, 0.61217, -0.19467,...    toothpaste  \n",
       "pepsodent     [-0.25594, 0.32515, -0.3657, 0.12705, -0.19359...    toothpaste  \n",
       "rembrandt     [0.83686, -0.4385, -0.43216, 0.61333, 0.38652,...    toothpaste  \n",
       "trident       [0.081471, 0.035272, 0.27418, 0.21987, -0.1931...    toothpaste  \n",
       "\n",
       "[390 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vec_df.shape   # (2485, 5)\n",
    "# vec_df[(lambda row : \",\" in row[\"Closest_Word\"],axis==1)]\n",
    "vec_df = vec_df[vec_df[\"Closest_Word\"].apply(lambda x: not isinstance(x, tuple))]\n",
    "# vec_df.shape   # (2413, 5)\n",
    "\n",
    "# for wordvec in ['Word2vec', 'Twitter', 'Wiki', 'CommonCrawl']:\n",
    "wordvec = 'Wiki'\n",
    "temp_df = vec_df[vec_df['WordVectorRef']==wordvec][[u'Closest_Word', u'Vector', u'Category']]\n",
    "temp_df = temp_df.reset_index()\n",
    "temp_df = temp_df.set_index(['Closest_Word'])\n",
    "\n",
    "# vec_df.WordVectorRef.unique()\n",
    "temp_dic = temp_df['Vector'].to_dict()\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['airlines', 'banks', 'batteries', 'beers', 'fast_food',\n",
       "       'headphone', 'hotel', 'jeans', 'laptop', 'shampoo', 'soft_drink',\n",
       "       'television', 'toothpaste', 'Greek_yogurt', 'auto_insurance',\n",
       "       'bar_soap', 'body_wash', 'bottled_water', 'breakfast_cereal',\n",
       "       'chewing_gum', 'energy_bar', 'energy_drink', 'gas_station',\n",
       "       'laundry_detergent', 'luxury_car', 'orange_juice', 'potato_chips',\n",
       "       'running_shoes', 'toilet_paper'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.Category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group three categories into one tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "luxurycar_hotel_gasstation_fastfood_df = temp_df[(temp_df['Category'] == \"fast_food\") |\n",
    "                                                 (temp_df['Category'] == \"hotel\") |\n",
    "                                                 (temp_df['Category'] == \"gas_station\") |\n",
    "                                                 (temp_df['Category'] == \"luxury_car\")]\n",
    "\n",
    "luxurycar_hotel_airlines_df = temp_df[(temp_df['Category'] == \"airlines\") |\n",
    "                                     (temp_df['Category'] == \"hotel\") |\n",
    "                                     (temp_df['Category'] == \"luxury_car\")]\n",
    "# luxurycar_hotel_gasstation_fastfood_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "savedf = luxurycar_hotel_airlines_df\n",
    "savedfname = \"luxurycar_hotel_airlines_df\"\n",
    "\n",
    "output_folder_path = \"data/tensorboard/\"\n",
    "glove_tsv_name = wordvec\n",
    "\n",
    "\n",
    "f_meta = open(\"{}{}_{}_words.tsv\".format(output_folder_path,glove_tsv_name,savedfname), \"w\")\n",
    "f_meta.write(\"Brand\"+\"\\t\"+\"Category\"+\"\\n\")\n",
    "# f_meta.write(\"\\t\")\n",
    "# f_meta.write(\"Category\")\n",
    "# f_meta.write(\"\\n\")\n",
    "f_dimension = open(\"{}{}_{}_vectors.tsv\".format(output_folder_path,glove_tsv_name,savedfname), \"w\")\n",
    "\n",
    "# for key, val in temp_dic.iteritems():\n",
    "for index, row in savedf.iterrows():\n",
    "    f_meta.write(index)\n",
    "    f_meta.write(\"\\t\")\n",
    "    f_meta.write(row['Category'])\n",
    "    f_meta.write(\"\\n\")\n",
    "    \n",
    "    val = row['Vector']\n",
    "    for dimension_val in val[:-1]:\n",
    "        #print(\"dimension_val {}, type {}\".format(dimension_val, type(dimension_val)))\n",
    "        f_dimension.write(str(dimension_val))\n",
    "        f_dimension.write(\"\\t\")\n",
    "    f_dimension.write(str(val[-1]))\n",
    "    f_dimension.write(\"\\n\")\n",
    "f_meta.close()\n",
    "f_dimension.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group gas_station and its descriptions into one tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['woman', 'rare', 'many', 'cheap', 'young', 'senior', 'expensive', 'man']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas_station_df = temp_df[(temp_df['Category'] == \"gas_station\")]\n",
    "gas_station_df\n",
    "\n",
    "with open(\"data/tensorboard/description_dict/gas_station_description_dict.pkl\",'rb') as f:\n",
    "    gas_station_description_dict = cPickle.load(f)\n",
    "gas_station_description_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'gas_station'\n",
    "savedf = gas_station_df\n",
    "savedfname = \"gas_station_df\"\n",
    "save_description_dict = gas_station_description_dict\n",
    "\n",
    "output_folder_path = \"data/tensorboard/\"\n",
    "glove_tsv_name = wordvec\n",
    "\n",
    "\n",
    "f_meta = open(\"{}{}_{}_words.tsv\".format(output_folder_path,glove_tsv_name,savedfname), \"w\")\n",
    "f_meta.write(\"Brand\"+\"\\t\"+\"Category\"+\"\\n\")\n",
    "# f_meta.write(\"\\t\")\n",
    "# f_meta.write(\"Category\")\n",
    "# f_meta.write(\"\\n\")\n",
    "f_dimension = open(\"{}{}_{}_vectors.tsv\".format(output_folder_path,glove_tsv_name,savedfname), \"w\")\n",
    "\n",
    "## write brands information to tsv\n",
    "for index, row in savedf.iterrows():\n",
    "    f_meta.write( index + \"(b)\")\n",
    "    f_meta.write(\"\\t\")\n",
    "    f_meta.write(row['Category'])\n",
    "    f_meta.write(\"\\n\")\n",
    "    \n",
    "    val = row['Vector']\n",
    "    for dimension_val in val[:-1]:\n",
    "        #print(\"dimension_val {}, type {}\".format(dimension_val, type(dimension_val)))\n",
    "        f_dimension.write(str(dimension_val))\n",
    "        f_dimension.write(\"\\t\")\n",
    "    f_dimension.write(str(val[-1]))\n",
    "    f_dimension.write(\"\\n\")\n",
    "    \n",
    "## write description_dict words to tsv\n",
    "for des in save_description_dict.keys():\n",
    "    f_meta.write(des + \"(adj)\")\n",
    "    f_meta.write(\"\\t\")\n",
    "    f_meta.write(\"adjective\")\n",
    "    f_meta.write(\"\\n\")\n",
    "    \n",
    "    vector = save_description_dict[des]\n",
    "    for dimension_val in vector[:-1]:\n",
    "        f_dimension.write(str(dimension_val))\n",
    "        f_dimension.write(\"\\t\")\n",
    "    f_dimension.write(str(val[-1]))\n",
    "    f_dimension.write(\"\\n\")\n",
    "    \n",
    "f_meta.close()\n",
    "f_dimension.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group hotel and its descriptions into one tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fine-dining',\n",
       " 'fastfood',\n",
       " 'rare',\n",
       " 'simple',\n",
       " 'many',\n",
       " 'young',\n",
       " 'beer',\n",
       " 'luxury',\n",
       " 'clean',\n",
       " 'senior',\n",
       " 'wine',\n",
       " 'dirty']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotel_df = temp_df[(temp_df['Category'] == \"hotel\")]\n",
    "hotel_df\n",
    "\n",
    "with open(\"data/tensorboard/description_dict/hotel_description_dict.pkl\",'rb') as f:\n",
    "    hotel_description_dict = cPickle.load(f)\n",
    "hotel_description_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'hotel'\n",
    "savedf = hotel_df\n",
    "savedfname = \"hotel_df\"\n",
    "save_description_dict = hotel_description_dict\n",
    "\n",
    "output_folder_path = \"data/tensorboard/\"\n",
    "glove_tsv_name = wordvec\n",
    "\n",
    "\n",
    "f_meta = open(\"{}{}_{}_words.tsv\".format(output_folder_path,glove_tsv_name,savedfname), \"w\")\n",
    "f_meta.write(\"Brand\"+\"\\t\"+\"Category\"+\"\\n\")\n",
    "# f_meta.write(\"\\t\")\n",
    "# f_meta.write(\"Category\")\n",
    "# f_meta.write(\"\\n\")\n",
    "f_dimension = open(\"{}{}_{}_vectors.tsv\".format(output_folder_path,glove_tsv_name,savedfname), \"w\")\n",
    "\n",
    "## write brands information to tsv\n",
    "for index, row in savedf.iterrows():\n",
    "    f_meta.write( index + \"(b)\")\n",
    "    f_meta.write(\"\\t\")\n",
    "    f_meta.write(row['Category'])\n",
    "    f_meta.write(\"\\n\")\n",
    "    \n",
    "    val = row['Vector']\n",
    "    for dimension_val in val[:-1]:\n",
    "        #print(\"dimension_val {}, type {}\".format(dimension_val, type(dimension_val)))\n",
    "        f_dimension.write(str(dimension_val))\n",
    "        f_dimension.write(\"\\t\")\n",
    "    f_dimension.write(str(val[-1]))\n",
    "    f_dimension.write(\"\\n\")\n",
    "    \n",
    "## write description_dict words to tsv\n",
    "for des in save_description_dict.keys():\n",
    "    f_meta.write(des + \"(adj)\")\n",
    "    f_meta.write(\"\\t\")\n",
    "    f_meta.write(\"adjective\")\n",
    "    f_meta.write(\"\\n\")\n",
    "    \n",
    "    vector = save_description_dict[des]\n",
    "    for dimension_val in vector[:-1]:\n",
    "        f_dimension.write(str(dimension_val))\n",
    "        f_dimension.write(\"\\t\")\n",
    "    f_dimension.write(str(val[-1]))\n",
    "    f_dimension.write(\"\\n\")\n",
    "    \n",
    "f_meta.close()\n",
    "f_dimension.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group fastfood and its descriptions into one tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fine-dining',\n",
       " 'take-out',\n",
       " 'slow',\n",
       " 'rare',\n",
       " 'precooked',\n",
       " 'nutrition',\n",
       " 'frozen',\n",
       " 'convenient',\n",
       " 'preheated',\n",
       " 'drive-through',\n",
       " 'save-a-lot',\n",
       " 'quick',\n",
       " 'fresh',\n",
       " 'many',\n",
       " 'healthy']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastfood_df = temp_df[(temp_df['Category'] == \"fast_food\")]\n",
    "fastfood_df\n",
    "\n",
    "with open(\"data/tensorboard/description_dict/fastfood_description_dict.pkl\",'rb') as f:\n",
    "    fastfood_description_dict = cPickle.load(f)\n",
    "fastfood_description_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = 'fast_food'\n",
    "savedf = fastfood_df\n",
    "savedfname = \"fastfood_df\"\n",
    "save_description_dict = fastfood_description_dict\n",
    "\n",
    "output_folder_path = \"data/tensorboard/\"\n",
    "glove_tsv_name = wordvec\n",
    "\n",
    "\n",
    "f_meta = open(\"{}{}_{}_words.tsv\".format(output_folder_path,glove_tsv_name,savedfname), \"w\")\n",
    "f_meta.write(\"Brand\"+\"\\t\"+\"Category\"+\"\\n\")\n",
    "# f_meta.write(\"\\t\")\n",
    "# f_meta.write(\"Category\")\n",
    "# f_meta.write(\"\\n\")\n",
    "f_dimension = open(\"{}{}_{}_vectors.tsv\".format(output_folder_path,glove_tsv_name,savedfname), \"w\")\n",
    "\n",
    "## write brands information to tsv\n",
    "for index, row in savedf.iterrows():\n",
    "    f_meta.write( index + \"(b)\")\n",
    "    f_meta.write(\"\\t\")\n",
    "    f_meta.write(row['Category'])\n",
    "    f_meta.write(\"\\n\")\n",
    "    \n",
    "    val = row['Vector']\n",
    "    for dimension_val in val[:-1]:\n",
    "        #print(\"dimension_val {}, type {}\".format(dimension_val, type(dimension_val)))\n",
    "        f_dimension.write(str(dimension_val))\n",
    "        f_dimension.write(\"\\t\")\n",
    "    f_dimension.write(str(val[-1]))\n",
    "    f_dimension.write(\"\\n\")\n",
    "    \n",
    "## write description_dict words to tsv\n",
    "for des in save_description_dict.keys():\n",
    "    f_meta.write(des + \"(adj)\")\n",
    "    f_meta.write(\"\\t\")\n",
    "    f_meta.write(\"adjective\")\n",
    "    f_meta.write(\"\\n\")\n",
    "    \n",
    "    vector = save_description_dict[des]\n",
    "    for dimension_val in vector[:-1]:\n",
    "        f_dimension.write(str(dimension_val))\n",
    "        f_dimension.write(\"\\t\")\n",
    "    f_dimension.write(str(val[-1]))\n",
    "    f_dimension.write(\"\\n\")\n",
    "    \n",
    "f_meta.close()\n",
    "f_dimension.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
